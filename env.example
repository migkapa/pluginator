# WordPress Plugin Generator Environment Configuration
# Copy this file to .env and fill in your API keys

# ===========================================
# REQUIRED: OpenAI Configuration (Default)
# ===========================================
OPENAI_API_KEY=your-openai-api-key-here

# ===========================================
# OPTIONAL: Alternative Model Providers
# ===========================================
# Only needed if you want to use non-OpenAI models

# Anthropic (Claude models)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Google (Gemini models)
GOOGLE_API_KEY=your-google-api-key-here

# Other providers (optional)
# GROQ_API_KEY=your-groq-api-key-here
# COHERE_API_KEY=your-cohere-api-key-here

# ===========================================
# Model Selection
# ===========================================
# DEFAULT_MODEL=gpt-4o                      # Default OpenAI model
# DEFAULT_MODEL=gpt-4o-mini                 # Faster OpenAI model
# DEFAULT_MODEL=claude-3-5-sonnet           # Anthropic shortcut
# DEFAULT_MODEL=gemini-2.0-flash            # Google shortcut

# Or use any LiteLLM model directly:
# DEFAULT_MODEL=litellm/anthropic/claude-3-5-sonnet-20241022
# DEFAULT_MODEL=litellm/groq/llama-3.1-70b-versatile
# DEFAULT_MODEL=litellm/cohere/command-r-plus

# ===========================================
# Advanced Configuration
# ===========================================
# Disable tracing (useful for non-OpenAI models)
# DISABLE_TRACING=false

# Use Chat Completions API instead of Responses API
# USE_CHAT_COMPLETIONS_API=false

# ===========================================
# Usage Examples
# ===========================================
# 1. Default usage (OpenAI GPT-4o):
#    Just set OPENAI_API_KEY
#
# 2. Use Claude with shortcut:
#    Set ANTHROPIC_API_KEY and DEFAULT_MODEL=claude-3-5-sonnet
#    Or use CLI: python main.py --model claude-3-5-sonnet
#
# 3. Use Gemini with shortcut:
#    Set GOOGLE_API_KEY and DEFAULT_MODEL=gemini-2.0-flash
#    Or use CLI: python main.py --model gemini-2.0-flash
#
# 4. Use any LiteLLM model:
#    python main.py --model litellm/groq/llama-3.1-8b-instant
#    python main.py --model litellm/cohere/command-r-plus
#
# 5. List available models and shortcuts:
#    python main.py --list-models 
# WordPress Plugin Generator - Environment Configuration
# Copy this file to .env and customize your settings

# ==============================================
# MODEL CONFIGURATION
# ==============================================

# Default model to use (can be overridden with --model flag)
# Examples:
#   OpenAI: gpt-4o, gpt-4o-mini, o1-preview, o1-mini
#   Ollama: ollama/llama3.2:latest, ollama/deepseek-r1:14b  
#   Claude: claude-3-5-haiku-20241022, claude-3-5-sonnet-20241022
#   Gemini: litellm/gemini/gemini-1.5-flash
#   Groq: litellm/groq/llama-3.1-70b-versatile
DEFAULT_MODEL=gpt-4o

# Default temperature (0.0-1.0, can be overridden with --temperature)
DEFAULT_TEMPERATURE=0.7

# ==============================================
# API KEYS
# ==============================================

# OpenAI API Key (required for OpenAI models)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API Key (required for Claude models)
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Google API Key (required for Gemini models)
# Get from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# Groq API Key (required for Groq models)
# Get from: https://console.groq.com/keys
GROQ_API_KEY=your-groq-api-key-here

# Cohere API Key (required for Cohere models)
# Get from: https://dashboard.cohere.ai/api-keys
COHERE_API_KEY=your-cohere-api-key-here

# ==============================================
# ADVANCED SETTINGS
# ==============================================

# Disable tracing (helpful for non-OpenAI models to avoid auth errors)
DISABLE_TRACING=false

# Use Chat Completions API instead of Responses API
USE_CHAT_COMPLETIONS_API=false

# ==============================================
# QUICK START EXAMPLES
# ==============================================

# For OpenAI models (default):
# DEFAULT_MODEL=gpt-4o
# OPENAI_API_KEY=sk-...

# For local Ollama (no API key needed):
# DEFAULT_MODEL=ollama/llama3.2:latest
# (Make sure Ollama is running: ollama serve)

# For Anthropic Claude:
# DEFAULT_MODEL=claude-3-5-haiku-20241022
# ANTHROPIC_API_KEY=sk-ant-...
# DISABLE_TRACING=true

# For Google Gemini:
# DEFAULT_MODEL=litellm/gemini/gemini-1.5-flash
# GOOGLE_API_KEY=AI...

# For Groq (ultra-fast):
# DEFAULT_MODEL=litellm/groq/llama-3.1-70b-versatile
# GROQ_API_KEY=gsk_...

# ==============================================
# TROUBLESHOOTING
# ==============================================

# If you get authentication errors with non-OpenAI models:
# 1. Set DISABLE_TRACING=true
# 2. Make sure your API key is correct
# 3. Check that you have sufficient credits/quota

# If Ollama models don't respond:
# 1. Make sure Ollama is running: ollama serve
# 2. Pull the model: ollama pull model-name
# 3. Try a larger model like deepseek-r1:14b

# For model performance issues:
# 1. Adjust temperature (lower = more focused)
# 2. Try different models for your use case
# 3. Use verbose mode: python main.py -v 